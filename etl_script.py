# -*- coding: utf-8 -*-
"""etl_script.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cT9ziM8a6iReAPntC-UCjXDJbpXeN143
"""

import pandas as pd
import psycopg2
import boto3
import json
from datetime import datetime
from decimal import Decimal
import io

# Configuration
RDS_HOST = "YOUR_RDS_HOST_NAME"
RDS_DBNAME = "YOUR_RDS_DBNAME"
RDS_USER = "YOUR_RDS_USER"
RDS_PASSWORD = "YOUR_RDS_PASSWORD"

DYNAMODB_TABLE_NAME = "YOUR_DYNAMODB_TABLE_NAME"
REGION_NAME = "YOUR_REGION_NAME"

CSV_FILE = "credit_card_transactions.csv"

def connect_rds():
    """Establishes a connection to the RDS PostgreSQL database."""
    print("Attempting to connect to RDS...")
    conn = psycopg2.connect(
        host=RDS_HOST,
        database=RDS_DBNAME,
        user=RDS_USER,
        password=RDS_PASSWORD
    )
    print("Successfully connected to RDS.")
    return conn

def create_rds_table(cursor):
    """Creates the 'transactions' table in RDS if it doesn't exist."""
    print("Checking/creating 'transactions' table in RDS...")
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS transactions (
            trans_date_trans_time TIMESTAMP,
            cc_num VARCHAR(255),
            merchant VARCHAR(255),
            category VARCHAR(255),
            amt DECIMAL(10, 2),
            city VARCHAR(255),
            state VARCHAR(255)
        );
    """)
    print("Table 'transactions' checked/created.")

def load_data_to_rds(df, rds_conn):
    """Loads a pandas DataFrame chunk into the RDS PostgreSQL 'transactions' table."""
    print(f"Loading {len(df)} rows to RDS...")
    buffer = io.StringIO()
    df_to_load = df[['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'city', 'state']]
    df_to_load.to_csv(buffer, index=False, header=False, sep='\t')
    buffer.seek(0)

    try:
        with rds_conn.cursor() as cursor:
            cursor.copy_from(buffer, 'transactions', sep='\t',
                             columns=('trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'city', 'state'))
        rds_conn.commit()
        print("Chunk loaded to RDS successfully.")
    except Exception as e:
        rds_conn.rollback()
        print(f"Error loading chunk to RDS: {e}")


def load_data_to_dynamodb(df):
    """Loads derived behavioral data into DynamoDB."""
    dynamodb = boto3.resource('dynamodb', region_name=REGION_NAME)
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)

    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], errors='coerce')
    df = df.dropna(subset=['trans_date_trans_time', 'cc_num', 'amt', 'category', 'city', 'state'])

    processed_count = 0
    for cc_num, group in df.groupby('cc_num'):
        if group.empty:
            continue


        if not group.empty:
            latest_transaction = group.sort_values(by='trans_date_trans_time', ascending=False).iloc[0]
        else:
            continue

        one_month_ago = datetime.now() - pd.DateOffset(months=1)
        total_spent = group[group['trans_date_trans_time'] >= one_month_ago]['amt'].sum()

        event_timestamp_str = latest_transaction['trans_date_trans_time'].isoformat()

        item = {
            'customer_id': str(cc_num),
            'event_timestamp': event_timestamp_str,
            'latest_transaction_timestamp': event_timestamp_str,
            'total_spent_last_month': Decimal(str(total_spent)),
            'most_common_category': group['category'].mode()[0] if not group['category'].empty else 'N/A',
            'last_merchant_city_state': f"{latest_transaction['city']}, {latest_transaction['state']}",
        }

        try:
            table.put_item(Item=item)
            processed_count += 1
        except Exception as e:
            print(f"DynamoDB put_item error for customer {cc_num}: {e}")
    print(f"Derived behavioral data for {processed_count} customers loaded to DynamoDB successfully for this chunk.")


if __name__ == "__main__":
    CHUNK_SIZE = 75000

    print(f"Starting ETL process with chunk size: {CHUNK_SIZE}")

    rds_conn = None
    try:

        rds_conn = connect_rds()
        rds_cursor = rds_conn.cursor()
        create_rds_table(rds_cursor)
        rds_cursor.close()

        for i, chunk_df in enumerate(pd.read_csv(CSV_FILE, chunksize=CHUNK_SIZE)):
            print(f"\n--- Processing chunk {i+1} (approx. {len(chunk_df)} rows) ---")

            # Data Cleaning & Preprocessing for the current chunk
            chunk_df.columns = chunk_df.columns.str.lower()
            # Ensure essential columns for processing are not null
            chunk_df = chunk_df.dropna(subset=['cc_num', 'trans_date_trans_time', 'amt', 'merchant', 'category', 'city', 'state'])

            # Load to RDS for the current chunk
            # Ensure there's data to load after cleaning
            if not chunk_df.empty:
                load_data_to_rds(chunk_df, rds_conn)
            else:
                print(f"Chunk {i+1} is empty after cleaning, skipping RDS load.")

            # Load to DynamoDB (derived behavioral data) for the current chunk
            if not chunk_df.empty:
                load_data_to_dynamodb(chunk_df)
            else:
                print(f"Chunk {i+1} is empty after cleaning, skipping DynamoDB load.")

    except Exception as e:
        print(f"Overall ETL process error: {e}")
    finally:
        if rds_conn:
            rds_conn.close()
            print("RDS connection closed.")

    print("\nETL process completed.")